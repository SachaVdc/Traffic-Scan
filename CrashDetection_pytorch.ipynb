{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5e9b688",
   "metadata": {},
   "source": [
    "# creation of the car crash detection model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7f3208",
   "metadata": {},
   "source": [
    "## Step 1 : Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832fa269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output, display\n",
    "import keyboard\n",
    "import time\n",
    "import torch.optim as optim\n",
    "# to install pytorch, follow instructions on https://pytorch.org/get-started/locally/\n",
    "# if CUDA is installed, this should allow GPU training\n",
    "# -> pip install torchsummary\n",
    "from torchsummary import summary\n",
    "print(torch.cuda.is_available())\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed56caae",
   "metadata": {},
   "source": [
    "## Step 2 : Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24a75a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLENAME = \"Train_Crash_Table.csv\"\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(TABLENAME)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca0db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the frame columns from the DataFrame\n",
    "frame_data = df[\"collision\"]\n",
    "\n",
    "# Flatten data into a single list\n",
    "labels = frame_data.values.flatten()\n",
    "print(labels)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acfad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"C:\\\\Users\\\\sacha\\\\OneDrive\\\\Bureau\\\\dataset\"\n",
    "BATCH_SIZE = int(len(labels))\n",
    "\n",
    "image_paths = list(Path(IMAGE_PATH).glob(\"*.jpg\"))[:BATCH_SIZE]\n",
    "print(image_paths[0])\n",
    "print(len(image_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b352ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 256\n",
    "img_height = 256\n",
    "\n",
    "# create a dataset class for the crash frames\n",
    "class CrashFrameDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None, csv_path=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.csv_path = csv_path\n",
    "\n",
    "        if self.csv_path:\n",
    "            self.df = pd.read_csv(self.csv_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.image_paths), len(self.labels))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = cv2.cvtColor(cv2.imread(str(image_path)), cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (img_width, img_height))\n",
    "        image = Image.fromarray(image.astype('uint8'))\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def toggle_label(self, idx):\n",
    "        # Toggle in memory\n",
    "        self.labels[idx] = 1 - self.labels[idx]\n",
    "\n",
    "        if self.csv_path:\n",
    "            # Reload CSV (optional, or use self.df directly if already loaded)\n",
    "            self.df.at[idx, 'collision'] = self.labels[idx]\n",
    "            self.df.to_csv(self.csv_path, index=False)\n",
    "\n",
    "    def count_accidents(self):\n",
    "        count_accidents = 0\n",
    "        count_non_accidents = 0\n",
    "        \n",
    "        for i in range(len(self)):\n",
    "            if self.labels[i] == 1:\n",
    "                count_accidents += 1\n",
    "            else:\n",
    "                count_non_accidents += 1\n",
    "        \n",
    "        return count_accidents, count_non_accidents\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Use the existing transform variable defined in a previous cell\n",
    "dataset = CrashFrameDataset(image_paths, labels, transform=transform, csv_path=TABLENAME)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0109e843",
   "metadata": {},
   "source": [
    "# Step 3: Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f72e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a matplotlib figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Initialize index to track the current image\n",
    "current_index = 0\n",
    "\n",
    "def update_image():\n",
    "    global current_index\n",
    "    image, label = dataset[current_index]\n",
    "    \n",
    "    # Convert tensor to numpy and transpose to (H, W, C) for imshow\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = image.cpu().numpy().transpose(1, 2, 0)\n",
    "    else:\n",
    "        image = np.array(image)\n",
    "        \n",
    "    ax.clear()\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(f\"Label: {label}\")\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(\"press 'right' to go to the next image, 'left' for previous, 'space' to toggle label, 'esc' to exit\")\n",
    "    display(fig)\n",
    "\n",
    "update_image()\n",
    "while True:\n",
    "    if keyboard.is_pressed(\"right\"): # Move to the next image (Right Arrow Key)\n",
    "        current_index = (current_index + 1) % len(image_paths)\n",
    "        update_image()\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    elif keyboard.is_pressed(\"left\"): # Move to the previous image (Left Arrow Key)\n",
    "        current_index = (current_index - 1) % len(image_paths)\n",
    "        update_image()\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    elif keyboard.is_pressed(\"space\"): # Toggle the label (Space Key)\n",
    "        dataset.toggle_label(current_index)\n",
    "        update_image()\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    elif keyboard.is_pressed(\"esc\"): # Exit the loop (Escape Key)\n",
    "        clear_output(wait=True)\n",
    "        print(\"Exiting the labeling tool.\")\n",
    "        count_accidents, count_non_accidents = dataset.count_accidents()\n",
    "        print(f\"Dataset : {len(dataset)} images ({count_accidents} accidents and {count_non_accidents} non-accidents)\")\n",
    "        plt.close(fig)\n",
    "        break\n",
    "\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3215cf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# recover accident and non-accident indices\n",
    "accident_indices = [i for i, label in enumerate(dataset.labels) if label == 1]\n",
    "non_accident_indices = [i for i, label in enumerate(dataset.labels) if label == 0]\n",
    "\n",
    "# Randomly sample from both classes to balance the dataset\n",
    "min_count = min(len(accident_indices), len(non_accident_indices))\n",
    "accident_sample = random.sample(accident_indices, min_count)\n",
    "non_accident_sample = random.sample(non_accident_indices, min_count)\n",
    "\n",
    "# shuffle the indices to ensure randomness\n",
    "balanced_indices = accident_sample + non_accident_sample\n",
    "random.shuffle(balanced_indices)\n",
    "\n",
    "# build the balanced dataset\n",
    "balanced_image_paths = [dataset.image_paths[i] for i in balanced_indices]\n",
    "balanced_labels = [dataset.labels[i] for i in balanced_indices]\n",
    "balanced_dataset = CrashFrameDataset(balanced_image_paths, balanced_labels, transform=dataset.transform)\n",
    "\n",
    "print(f\"Balanced dataset : {len(balanced_dataset)} images ({min_count} accidents and {min_count} non-accidents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aae6b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train-test split ratio\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * len(balanced_dataset))\n",
    "test_size = len(balanced_dataset) - train_size\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_dataset, test_dataset = random_split(balanced_dataset, [train_size, test_size])\n",
    "\n",
    "print(f\"train dataset : {len(train_dataset)} images and test dataset : {len(test_dataset)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe5e41e",
   "metadata": {},
   "source": [
    "# Step 4: Build a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b630353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrashDetection(nn.Module):\n",
    "    def __init__(self, input_channels=3, filter_base=8, input_height=256, input_width=256):\n",
    "        super(CrashDetection, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.filter_base = filter_base\n",
    "        self.input_height = input_height\n",
    "        self.input_width = input_width\n",
    "\n",
    "        # CNN layers\n",
    "        self.conv1_1 = nn.Conv2d(input_channels, filter_base, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(filter_base, filter_base, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=4)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(filter_base, filter_base * 2, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(filter_base * 2, filter_base * 2, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=4)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(filter_base * 2, filter_base * 4, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(filter_base * 4, filter_base * 4, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Placeholder for output size\n",
    "        self._to_linear = None\n",
    "        self._compute_flattened_size()\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 128)\n",
    "        self.fc2 = nn.Linear(128, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def _compute_flattened_size(self):\n",
    "        with torch.no_grad():\n",
    "            x = torch.zeros(1, self.input_channels, self.input_height, self.input_width)\n",
    "            x = F.relu(self.conv1_1(x))\n",
    "            x = F.relu(self.conv1_2(x))\n",
    "            x = self.pool1(x)\n",
    "\n",
    "            x = F.relu(self.conv2_1(x))\n",
    "            x = F.relu(self.conv2_2(x))\n",
    "            x = self.pool2(x)\n",
    "\n",
    "            x = F.relu(self.conv3_1(x))\n",
    "            x = F.relu(self.conv3_2(x))\n",
    "            x = self.pool3(x)\n",
    "\n",
    "            self._to_linear = x.view(1, -1).shape[1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = self.pool1(x)\n",
    "        #print('Output shape of layer 1', x.shape)\n",
    "\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.pool2(x)\n",
    "        #print('Output shape of layer 2', x.shape)\n",
    "\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = self.pool3(x)\n",
    "        #print('Output shape of layer 3', x.shape)\n",
    "\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        #print('Shape required to pass to Linear Layer', x.shape)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = CrashDetection(input_channels=3, filter_base=8, input_height=img_height, input_width=img_width).to(device)\n",
    "summary(model, (3, img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5787e7fa",
   "metadata": {},
   "source": [
    "# Step 5: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aea3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 16\n",
    "\n",
    "loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_history = []\n",
    "accuracy_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(loader):\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Ensure labels are in the correct format\n",
    "        if labels.max() > 1:\n",
    "            labels = labels / 255.0\n",
    "        \n",
    "        labels = labels.unsqueeze(1).float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # prediction and accuracy calculation\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "\n",
    "    loss_history.append(epoch_loss)\n",
    "    accuracy_history.append(epoch_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfec15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plot loss on the primary y-axis\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss', color='tab:blue')\n",
    "ax1.plot(loss_history, label='Loss', color='tab:blue')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "# Create a secondary y-axis for accuracy\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Accuracy', color='tab:orange')\n",
    "ax2.plot(accuracy_history, label='Accuracy', color='tab:orange')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:orange')\n",
    "\n",
    "# Add a title and show the plot\n",
    "plt.title('Training Loss and Accuracy')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e219b7",
   "metadata": {},
   "source": [
    "# Step 6 : Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5cbde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "total_loss = 0.0\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_images, test_labels in test_loader:\n",
    "        test_images = test_images.to(device)\n",
    "        test_labels = test_labels.to(device).unsqueeze(1).float()\n",
    "\n",
    "        outputs = model(test_images)\n",
    "        loss = criterion(outputs, test_labels)\n",
    "        total_loss += loss.item() * test_images.size(0)\n",
    "\n",
    "        predicted_labels = (torch.sigmoid(outputs) > 0.5).float()\n",
    "\n",
    "        # Store predictions and targets for later analysis\n",
    "        all_preds.extend(predicted_labels.cpu().numpy())\n",
    "        all_targets.extend(test_labels.cpu().numpy())\n",
    "\n",
    "        total_correct += (predicted_labels == test_labels).sum().item()\n",
    "        total_samples += test_labels.size(0)\n",
    "\n",
    "# Calculate average loss and accuracy\n",
    "avg_loss = total_loss / total_samples\n",
    "accuracy = total_correct / total_samples\n",
    "\n",
    "print(f'Test loss: {avg_loss:.4f}, Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccee8cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(classification_report(all_targets, all_preds, digits=4))\n",
    "print(f\"Accuracy: {accuracy_score(all_targets, all_preds):.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=[\"No Crash\", \"Crash\"], \n",
    "            yticklabels=[\"No Crash\", \"Crash\"])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d855cc",
   "metadata": {},
   "source": [
    "# Step 7 : Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60e3dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "torch.save(model.state_dict(), f\"Models/CarCrashPytorch_{timestamp}.keras\")\n",
    "print(f\"Model saved as CarCrashPytorch_{timestamp}.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6426755",
   "metadata": {},
   "source": [
    "# Step 8 : Load and try the model with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f463f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "model_paths = glob.glob(\"Models/CarCrashPytorch_*.keras\")\n",
    "model_path = model_paths[len(model_paths) - 1]\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "\n",
    "model2 = CrashDetection().to(device)\n",
    "model2.load_state_dict(torch.load(model_path))\n",
    "model2.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e244363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewData = cv2.cvtColor(cv2.imread('NewCrash.jpg'), cv2.COLOR_BGR2RGB)\n",
    "NewData = cv2.resize(NewData,(256,256))\n",
    "plt.imshow(NewData)\n",
    "NewData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca22994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess the NewData\n",
    "NewData_tensor = torch.tensor(NewData, dtype=torch.float32).permute(2, 0, 1).to(device) / 255.0  # Normalize to [0, 1]\n",
    "NewData_tensor.shape\n",
    "# Set the model to evaluation mode\n",
    "model2.eval()\n",
    "\n",
    "# Perform prediction\n",
    "with torch.no_grad():\n",
    "    y_sigmoid = model2(NewData_tensor.unsqueeze(0))\n",
    "    y_pred = (torch.sigmoid(y_sigmoid) > 0.5).int().cpu().numpy().item()\n",
    "\n",
    "if y_pred == 0:\n",
    "    print(f\"No crash detected\") \n",
    "else:\n",
    "    print(f\"Crash detected \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
